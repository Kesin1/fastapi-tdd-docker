* Tortoise ORM

  - ORM = [[https://en.wikipedia.org/wiki/Objectâ€“relational_mapping][Object-relational Mapping]]
    - programming technique for cnoverting dataa between incompatible type
      systems using object-oriented programming
    - [[https://blog.bitsrc.io/what-is-an-orm-and-why-you-should-use-it-b2b6f75f5e2a][What is an ORM and Why You Should Use it]]
    - solution to the idea of: Using language of choice instead of SQL
      - using object-oriented paradigm of this language
      - example using javascript
        #+begin_src javascript
          // SELECT * FROM users WHERE email = 'test@test.com';

          var orm = require('generic-orm-libarry');
          var user = orm("users").where({ email: 'test@test.com' });
        #+end_src

  - pros:
    - write in your language
    - abstracts away the database systems (MySQL == PostgreSQL)
    - advanced features (support for transactions / connection pooling /
      migrations / seeds / streams)
    - many of the queries you will write will perform better if you wrote them
      yourself
  - cons:
    - not so beneficiant if you're a master at SQL
    - overhead involved in learning the ORM
    - initial configuration is a headache
    - you don't know exactly what's going on under the hood

** Database Migrations (via Aerich)

  - Tortoise supports [[https://en.wikipedia.org/wiki/Schema_migration][database migrations]] via [[https://github.com/tortoise/aerich][Aerich]]. Let's take a few steps back and configure it.
    https://tortoise-orm.readthedocs.io/en/latest/migration.html
  - creates  migration.sql files in migrations/models
    
* Setup Pytest

  - Setup tests directory (__init__, conftest, test_ping)
  - by default pytest auto-discovers files in tests that start or end with test_ or _test
  - Test funcitons must begin with test_, classes must also begin with Test

** Fixtures

   - Fixtures are reusable objects for tests
     - they have a scope associated with them, that indicates how often the
       fixture is invoked
       1. function - once per test_function (default)
       2. class - once per test class
       3. module - once per test module
       4. session - once per test session
     - [[https://pybit.es/articles/pytest-fixtures/][All You Need to Know to Start Using Fixtures in Your pytest Code]]
     - [[https://pybit.es/articles/pytest-book/][Python Testing With Pytest]]
          
   - define a conftest fixture in conftest
   - we import *Starlette's TestClient*, which uses the *Requests* library to
     make requests against the FastAPI app
   - we orverride the dependency, setting testing to 1 (dependency_overrides is
     a variable in fastapi.FastAPI app
     - is a dict of {dependency_name : value_what_we_like_to_override_with}
       - key: get_settings
       - value: get_settings_override
         
*** The test_app fixture

    - all code before *yield* serves as setup code, everything after as teardown
      [[https://docs.pytest.org/en/latest/explanation/fixtures.html#improvements-over-xunit-style-setup-teardown-functions][Fixture finalization / executing teardown code]]
    - we use the fixture by passing it to the test_function

      
** Given-When-Then

   - logical framework - makes it easier and faster to write tests
     
   | State | Explanation                   | Code                  |
   |-------+-------------------------------+-----------------------|
   | Given | the state of the application  | setup code, fixtures, |
   |       | before the test runs          | dadabase state        |
   | When  | the behavior/login being      | code under test       |
   |       | tested                        |                       |
   | Then  | the expected changes based on | asserts               |
   |       | the behavior                  |                       |

   - Example:
     #+begin_src python
       def test_ping(test_app):
           # Given
           # test_app

           # When
           response = test_app.get("/ping")

           # Then
           assert response.status_code == 200
           assert response.json() == {"environment": "dev", "ping": "pong!", "testing": True}
     #+end_src

* App Structure
** APIRouter
  - adding *FastAPIRouter*, *database init function* and a *Pydantic* model

  - routes in particular *api Folder*
    - remove old route
    - include the route into the application
    - use function to initialize new app

  - update test_app
    - app = create_application(); then replace

  - You can break up and modularize larger projects as well as apply versioning
    to your API with the APIRouter. If you're familiar with Flask, it's
    equivalent to a Blueprint. 

** Database Init

   - moving register_tortoise helper to function init_db inside
     project/app/db.py to clean up project/app/main.py
   - adding [[https://fastapi.tiangolo.com/advanced/events/][Event Handlers]] *Startup* and *Shutdown*
     - You can define event handlers (functions) that need to be executed before
       the application starts up, or when the application is shutting down. 
   - then calling init_db when there is the event "startup"

*** Apply schema to the database in its final state

    - add generate_schema function to db.py
    - generate_schema calls Tortoise.init to set up Tortoise and then generates
      the schema
    - since we want to use Aerich in the database schema, bring the containers
      and colums down again

      
** Pydantic

   - first time using [[https://pydantic-docs.helpmanual.io][Pydantic]]?

* RESTful Routes

  | Endpoint       | HTTP Method | CRUD Method | Result               |
  |----------------+-------------+-------------+----------------------|
  | /summaries     | GET         | READ        | get all summaries    |
  | /summaries/:id | GET         | READ        | get a single summary |
  | /summaries     | POST        | CREATE      | add a summary        |

  For each we'll do:
  1. write a test
  2. run the test, to ensure it fails (red)
  3. write just enough code to get the test to pass (green)
  4. refactor (if necessary)

** Procedure with new routes
   1. Write a test (asserting 200 to status code - will therefore fail)
   2. Ensure that the test fails
   3. Add the handler

      
* Selecting Tests
  - For example, to run all tests that have ping in their names:
    pytest -k ping
  - docker-compose exec web python -m pytest -k read
    only tests with read inside the name

  
** Useful Pytest commands

   # normal run
   $ docker-compose exec web python -m pytest

   # disable warnings
   $ docker-compose exec web python -m pytest -p no:warnings

   # run only the last failed tests
   $ docker-compose exec web python -m pytest --lf

   # run only the tests with names that match the string expression
   $ docker-compose exec web python -m pytest -k "summary and not test_read_summary"

   # stop the test session after the first failure
   $ docker-compose exec web python -m pytest -x

   # enter PDB after first failure then end the test session
   $ docker-compose exec web python -m pytest -x --pdb

   # stop the test run after two failures
   $ docker-compose exec web python -m pytest --maxfail=2

   # show local variables in tracebacks
   $ docker-compose exec web python -m pytest -l

   # list the 2 slowest tests
   $ docker-compose exec web python -m pytest --durations=2

* POST Routes
** First Route summaries.py

   - Here, we defined a handler that expects a payload, payload:
     SummaryPayloadSchema, with a URL.
   - Essentially, when the route is hit with a POST request, FastAPI will read
     the body of the request and validate the data:
     - If valid, the data will be available in the payload parameter.
     - FastAPI also generates [[https://json-schema.org][JSON Schema]] definitions that are then used to
       automatically generate the OpenAPI schema and the API documentation.
     - If invalid, an error is immediately returned.

   - added utility function for creating new summaries
     1. Creates a new TextSummary instance
     2. Returns the generated ID

   - next wire the routes
     - Take note of the prefix URL along with the "summaries" tag, which will be
       applied to the OpenAPI schema (for grouping operations). 


   #+begin_src bash
     $ http --json POST http://localhost:8004/summaries/ url=http://testdriven.io

     # Output
     HTTP/1.1 201 Created
     content-length: 37
     content-type: application/json
     date: Mon, 13 Sep 2021 06:43:16 GMT
     server: uvicorn

     {
         "id": 3,
         "url": "http://testdriven.io"
     }
   #+end_src

** Test

   - test_summaries.py to project/tests
     - first test that it returns what you expect
     - adding new fixture to conftest


* Parametrizing Test Functions

  - Parametrized tests allow a developer to run the same test multiple times
    with different data inputs
    #+begin_src python
      def test_update_summary_incorrect_id(test_app_with_db):
          response = test_app_with_db.put(
              "/summaries/999/",
              data=json.dumps({"url": "https://foo.bar", "summary": "updated!"})
          )
          assert response.status_code == 404
          assert response.json()["detail"] == "Summary not found"

          response = test_app_with_db.put(
              f"/summaries/0/",
              data=json.dumps({"url": "https://foo.bar", "summary": "updated!"})
          )
          assert response.status_code == 422
          assert response.json() == {
              "detail": [
                  {
                      "loc": ["path", "id"],
                      "msg": "ensure this value is greater than 0",
                      "type": "value_error.number.not_gt",
                      "ctx": {"limit_value": 0},
                  }
              ]
          }


      def test_update_summary_invalid_json(test_app_with_db):
          response = test_app_with_db.post(
              "/summaries/", data=json.dumps({"url": "https://foo.bar"})
          )
          summary_id = response.json()["id"]

          response = test_app_with_db.put(
              f"/summaries/{summary_id}/",
              data=json.dumps({})
          )
          assert response.status_code == 422
          assert response.json() == {
              "detail": [
                  {
                      "loc": ["body", "url"],
                      "msg": "field required",
                      "type": "value_error.missing",
                  },
                  {
                      "loc": ["body", "summary"],
                      "msg": "field required",
                      "type": "value_error.missing",
                  }
              ]
          }


      def test_update_summary_invalid_keys(test_app_with_db):
          response = test_app_with_db.post(
              "/summaries/", data=json.dumps({"url": "https://foo.bar"})
          )
          summary_id = response.json()["id"]

          response = test_app_with_db.put(
              f"/summaries/{summary_id}/",
              data=json.dumps({"url": "https://foo.bar"})
          )
          assert response.status_code == 422
          assert response.json() == {
              "detail": [
                  {
                      "loc": ["body", "summary"],
                      "msg": "field required",
                      "type": "value_error.missing",
                  }
              ]
          }

          response = test_app_with_db.put(
              f"/summaries/{summary_id}/",
              data=json.dumps({"url": "invalid://url", "summary": "updated!"})
          )
          assert response.status_code == 422
          assert response.json()["detail"][0]["msg"] == "URL scheme not permitted"
    #+end_src

  - test really differ only in their inputs and expected outputs, therefore we
    can get rid of a lot of code -> pytest.mark.parametrize

    #+begin_src python
      @pytest.mark.parametrize("summary_id, payload, status_code, detail", [
          [999, {"url": "https://foo.bar", "summary": "updated!"}, 404, "Summary not found"],
          [0,
           {"url": "https://foo.bar", "summary": "updated!"}
           422,
          [{"loc": ["path", "id"], "msg": "ensure this value is greater than 0", "type": "value_error.number.not_gt", "ctx": {"limit_value": 0}}]
          ],
          [
              1,
              {},
              422,
              [
                  {"loc": ["body", "url"], "msg": "field required", "type": "value_error.missing"},
                  {"loc": ["body", "summary"], "msg": "field required", "type": "value_error.missing"}
              ]
          ],
          [
              1,
              {"url": "https://foo.bar"},
              422,
              [{"loc": ["body", "summary"], "msg": "field required", "type": "value_error.missing"}]
          ]
      ])
      def test_update_summary_invalid(test_app_with_db, summary_id, payload, status_code, detail):
          response = test_app_with_db.put(
              f"/summaries/{summary_id}/",
              data=json.dumps(payload)
          )
          assert response.status_code == status_code
          assert response.json()["detail"] == detail
    #+end_src

